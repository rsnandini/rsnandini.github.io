<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" hreflang="en" /><updated>2023-06-09T17:16:52-07:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
</subtitle><entry><title type="html">Which Features are Learnt by Contrastive Learning?</title><link href="http://localhost:4000/blog/2023/CC-FS/" rel="alternate" type="text/html" title="Which Features are Learnt by Contrastive Learning?" /><published>2023-06-08T12:53:00-07:00</published><updated>2023-06-08T12:53:00-07:00</updated><id>http://localhost:4000/blog/2023/CC-FS</id><content type="html" xml:base="http://localhost:4000/blog/2023/CC-FS/"><![CDATA[<p>Contrastive learning (CL) has emerged as a powerful technique for representation learning, with or without label supervision. However, supervised CL is prone to collapsing representations of subclasses within a class by not capturing all their features, and unsupervised CL may suppress harder class-relevant features by focusing on learning easy class-irrelevant features; both significantly compromise representation quality. Yet, there is no theoretical understanding of class collapse or feature suppression at test time. We provide the first unified theoretically rigorous framework to determine which features are learnt by CL. Our analysis indicate that, perhaps surprisingly, bias of (stochastic) gradient descent towards finding simpler solutions is a key factor in collapsing subclass representations and suppressing harder class-relevant features. Moreover, we present increasing embedding dimensionality and improving the quality of data augmentations as two theoretically motivated solutions to feature suppression. We also provide the first theoretical explanation for why, when supervised and unsupervised CL are employed together, higher-quality representations are obtained, even using commonly-used stochastic gradient methods.</p>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/example_cc_fs.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>

<h2> Main Results </h2>

<h3> Class Collapse </h3>

<hr />

<ol>
  <li>Not all minimizers of the SCL loss exhibit CC, but the minimum norm minimizer does. The key insight is that due to high dimensionality of the model, it has the capacity to minimize the training loss in various ways. While minimizing the training loss implies CC on the training data, it does not necessarily imply CC on the test data. The first figure provides a simplified example illustrating a model that exhibits CC on the training data but not on the test data. This occurs because the model can exploit the specific input noise present in the training data to counteract the subclass information in the embeddings, while this input noise is rarely encountered in the overall distribution due to high dimensionality. The second figure illustrates that the minimum norm minimizer does not align with the subclass feature at all.</li>
</ol>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/not_all.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/fs.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>

<ol>
  <li>In SCL, subclasses are learned by (S)GD early in training but unlearned later. The first part is supported by both theoretical and empirical results and the second part is supported by empirical results. The theoretical characterization of the unlearning process remains an important direction for future research. This observation, in conjunction with the previous point (1), prompts us to conjecture that the bias of (S)GD towards simpler solutions, such as the minimum norm solution, leads to the unlearning of subclasses and ultimately results in class collapse (CC).</li>
</ol>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cc.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>

<h3> Feature Suppresion </h3>
<hr />
<p>In UCL, with the min norm inductive bias, we characeterize two scenarios where FS can happen. (a) When there are easy and irrelevant features present, and the embedding size is limited, the model is unable to accommodate all the information from the input space into the embeddings. As a result, it selectively captures only the easiest features, disregarding the harder class-relevant ones. This suggests increasing embedding size as a solution which we validated through experiments. (b) Even with arbitrarily large embedding sizes, FS can still occur in the presence of high-dimensional irrelevant features and the use of imperfect data augmentation that preserves those features. This emphasizes the importance of designing better data augmentation strategy.</p>

<h3> Joint Loss </h3>
<hr />
<p>We also theotretically justify using a weighted sum of SCL and UCL losses, showing that it can provably avoid both CC and FS. This result sheds light on the empirical observation of improved performance when joint loss is used.</p>

<h4> BibTeX </h4>

<div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@article{xue2023features,
  title={Which Features are Learnt by Contrastive Learning? On the Role of Simplicity Bias in Class Collapse and Feature Suppression},
  author={Xue, Yihao and Joshi, Siddharth and Gan, Eric and Chen, Pin-Yu and Mirzasoleiman, Baharan},
  journal={arXiv preprint arXiv:2305.16536},
  year={2023}
}
</code></pre></div></div>]]></content><author><name></name></author><category term="contrastive-learning" /><category term="simplicity-bias" /><summary type="html"><![CDATA[On the Role of Simplicity Bias in Class Collapse and Feature Suppression]]></summary></entry><entry><title type="html">Data-Efficient Contrastive Self-supervised Learning</title><link href="http://localhost:4000/blog/2023/data-CL/" rel="alternate" type="text/html" title="Data-Efficient Contrastive Self-supervised Learning" /><published>2023-05-13T12:53:00-07:00</published><updated>2023-05-13T12:53:00-07:00</updated><id>http://localhost:4000/blog/2023/data-CL</id><content type="html" xml:base="http://localhost:4000/blog/2023/data-CL/"><![CDATA[<p>Self-supervised learning (SSL) learns high-quality representations from large pools of unlabeled training data. As datasets grow larger, it becomes crucial to identify the examples that contribute the most to learning such representations. This enables efficient SSL by reducing the volume of data required for learning high-quality representations. Nevertheless, quantifying the value of examples for SSL has remained an open question. In this work, we address this for the first time, by proving that examples that contribute the most to contrastive SSL are those that have the most similar augmentations to other examples, in expectation. We provide rigorous guarantees for the generalization performance of SSL on such subsets. Empirically, we discover, perhaps surprisingly, the subsets that contribute the most to SSL are those that contribute the least to supervised learning. Through extensive experiments, we show we can safely exclude 20% of examples from CIFAR100 and 40% from STL10 and TinyImageNet, without affecting downstream task performance. We also show that our subsets outperform random subsets by more than 2% on CIFAR10. We also demonstrate that these subsets are effective across contrastive SSL methods (evaluated on SimCLR, MoCo, SimSiam, BYOL).</p>

<h2>Highlights</h2>
<h3>New Problem</h3>
<hr />
<p>Previous work has studied data-efficiency for supervised learning and shown that nearly 30% of examples can be discarded on many datasets without sacrificing accuracy. However, this problem has not been studied for self-supervised learning. Our paper proposes the first empirical and theoretical method for data-efficient contrastive learning. We show that across various datasets (CIFAR100, STL10 and TinyImageNet), our method allows you to discard 20-40% of examples without affecting downstream classification accuracy.</p>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/discard-pct.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>

<h3>Theoretical Guarantees for Downstream Accuracy</h3>
<hr />
<p>We use [Huang et al. 2023] theoretical characterization of contrastive learning using alignment and divergence of class centers to show that the subset we choose preserves alignment and divergence of class centers and thus preserves downstream accuracy.</p>

<h4> BibTeX </h4>
<div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@article{joshi2023dataefficient,
    title={Data-Efficient Contrastive Self-supervised Learning: Most Beneficial Examples for Supervised Learning Contribute the Least},
    author={Joshi, Siddharth and Mirzasoleiman, Baharan},
    journal={International Conference on Machine Learning (ICML)},
    year={2023}
}
</code></pre></div></div>

<h4> Code </h4>
<div class="repositories d-flex flex-wrap flex-md-row flex-column justify-content-between align-items-center">
  



<div class="repo p-2 text-center">
  <a href="https://github.com/BigML-CS-UCLA/sas-data-efficient-contrastive-learning">
    <img class="repo-img-light w-100" alt="BigML-CS-UCLA/sas-data-efficient-contrastive-learning" src="https://github-readme-stats.vercel.app/api/pin/?username=BigML-CS-UCLA&amp;repo=sas-data-efficient-contrastive-learning&amp;theme=default&amp;show_owner=true" />
    <img class="repo-img-dark w-100" alt="BigML-CS-UCLA/sas-data-efficient-contrastive-learning" src="https://github-readme-stats.vercel.app/api/pin/?username=BigML-CS-UCLA&amp;repo=sas-data-efficient-contrastive-learning&amp;theme=dark&amp;show_owner=true" />
  </a>
</div>

</div>]]></content><author><name></name></author><category term="data-efficiency" /><category term="contrastive-learning" /><summary type="html"><![CDATA[Most Beneficial Examples for Supervised Learning Contribute the Least]]></summary></entry></feed>